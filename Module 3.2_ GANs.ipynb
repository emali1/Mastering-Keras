{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "GANs.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k41yObzZqnZR"
      },
      "source": [
        "##GANs for Synthetic Data Generation\n",
        "\n",
        "We implement a Generative Adversarial Network (GAN) in the Keras functional API. In this module we will pay attention to:\n",
        "\n",
        "- Implementing the GAN architecture in Keras.\n",
        "- Training our model.\n",
        "- Using our model to generate synthetic data.\n",
        "\n",
        "Note that we will not spend time tuning hyper-parameters: The purpose is to show how different techniques can be implemented in Keras, not to solve particular data science problems as optimally as possible. Obviously, most techniques include hyper-parameters that need to be tuned for optimal performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G85xmpAOzgZL",
        "outputId": "3a6ccda3-71e4-4e4e-fd88-5c154a2fedb8"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May  8 03:06:11 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    34W / 250W |   5385MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNgL43-KrJgf"
      },
      "source": [
        "We import required libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVH7UR5EqnZU"
      },
      "source": [
        "from keras.datasets.mnist import load_data\n",
        "from keras import Model\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Input,Dense,Conv2D,Flatten,Dropout,LeakyReLU,Reshape,Conv2DTranspose\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.callbacks import EarlyStopping\n",
        "from statistics import mean\n",
        "\n",
        "from matplotlib import pyplot\n",
        "\n",
        "import numpy as np\n",
        "import numpy.random as rng\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dMkvBeRrZpd"
      },
      "source": [
        "As in the denoising auto-encoder module, we will be working with the MNIST data. These are 28x28 greyscale images of handwritten digits (0-9). The classes are the digit. \n",
        "\n",
        "This data is included in Keras.datasets library, so it is easy to load. We will expand the image dimension so that we have a single channel (as it is greyscale we have only one channel), and normalize the pixel values to real numbers between 0 and 1.\n",
        "\n",
        "We will only work with the training data, and so will create a function that pre-processes and returns that. If you want to look at the data, examine the code in module 2.4, as this provides functions for viewing the MNIST images with their class labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f5XCjFuqnZa"
      },
      "source": [
        "def get_data ():\n",
        "  # load the images into memory\n",
        "  (trainX, trainy), (testX, testy) = load_data()\n",
        "  # We will only really work with the trainX data.\n",
        "  # Let's expand it to add channel dimension\n",
        "  X = np.expand_dims(trainX, axis=-1)\n",
        "  # Convert from unsigned ints to floats and scale to between 0 and 1.\n",
        "  X = X.astype('float32')\n",
        "  X = X / 255.0\n",
        "  return X"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xWZXMXBs1l4"
      },
      "source": [
        "We call our get data function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRFxVACts367"
      },
      "source": [
        "X=get_data()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRzl8kQas8bd"
      },
      "source": [
        "We want our discriminator to train on batches of real and fake images, learning to distinguish between the two. So we need a function to grab a set of real images from our MNIST image data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1qqqMVbqnZg"
      },
      "source": [
        "# select real samples\n",
        "def select_real_images(dataset, n_samples):\n",
        "    # choose random instances\n",
        "    indices = rng.randint(0, dataset.shape[0], n_samples)\n",
        "    # retrieve selected images\n",
        "    X = dataset[indices]\n",
        "    # generate 'real' class labels (1)\n",
        "    y = np.ones((n_samples, 1))\n",
        "    return X, y"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJz1IZLPtQRf"
      },
      "source": [
        "Now let us define a function to create our discriminator model. We will also compile it within the function, so if you want to play around with the optimizer change the code in here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D9l2VbrqnZi"
      },
      "source": [
        "def get_discriminator(in_shape=(28,28,1)):\n",
        "  # Define Model\n",
        "  # This is a basic binary classification CNN\n",
        "  inputs=Input(in_shape)\n",
        "  \n",
        "  conv1=Conv2D(128, 5, strides=2, padding='same')(inputs)\n",
        "  leak1=LeakyReLU(alpha=.2)(conv1)\n",
        "  drop1=Dropout(.4)(leak1)\n",
        "  \n",
        "  conv2=Conv2D(64, 5, strides=2, padding='same')(drop1)\n",
        "  leak2=LeakyReLU(alpha=.2)(conv2)\n",
        "  drop2=Dropout(.4)(leak2)\n",
        "  \n",
        "  flat=Flatten()(drop2)\n",
        "  outputs=Dense(1,activation='sigmoid')(flat)\n",
        "  \n",
        "  # Create Model\n",
        "  model=Model(inputs=inputs,outputs=outputs)\n",
        "  \n",
        "  # Compile model\n",
        "  opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPd9LvFcxjkQ"
      },
      "source": [
        "If you wish, run the following code block to create an instance of the discriminator model in order to view a summary.\n",
        "\n",
        "Note we will create the discriminator instance we use for the problem in a later code block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRHyHrftqnZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2c0a9e-b5c7-4c49-c5a5-7b0d1c77c721"
      },
      "source": [
        "# Get the discriminator\n",
        "discriminator = get_discriminator()\n",
        "# View a summary of the discriminator\n",
        "discriminator.summary()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 14, 14, 128)       3328      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 7, 7, 64)          204864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 3137      \n",
            "=================================================================\n",
            "Total params: 211,329\n",
            "Trainable params: 211,329\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZH_OmoaqnZn"
      },
      "source": [
        "def get_generator(noise_dim=100):\n",
        "    # Define the generator model\n",
        "    inputs=Input((noise_dim,))\n",
        "    \n",
        "    # Create a basis for 7x7 image\n",
        "    # We are using the noise to generate 128 high level 'feature maps' in a 7x7 space\n",
        "    n = 128 * 7 * 7\n",
        "    dense = Dense(n)(inputs)\n",
        "    leak1 = LeakyReLU(alpha=0.2)(dense)\n",
        "    reshape = Reshape((7, 7, 128))(leak1)\n",
        "    \n",
        "    # Now we extract lower level features...\n",
        "    # Upsample to 14x14\n",
        "    conv_tran1 = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same')(reshape)\n",
        "    leak2=LeakyReLU(alpha=0.2)(conv_tran1)\n",
        "    \n",
        "    # Now we extract even lower level features...\n",
        "    # Upsample to 28x28\n",
        "    conv_tran2 = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same')(leak2)\n",
        "    leak3 = LeakyReLU(alpha=0.2)(conv_tran2)\n",
        "    \n",
        "    # Finally we put togeather our pixel values for the synthetic image\n",
        "    outputs = Conv2D(1, (7,7), activation='sigmoid', padding='same')(leak3)\n",
        "    \n",
        "    # Create the model and return it\n",
        "    model=Model(inputs=inputs,outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfKSwEBBxIgM"
      },
      "source": [
        "If you wish, run the following code block to create an instance of the generator model in order to view a summary. You can change the dimension of the noise vector if you like.\n",
        "\n",
        "Note we will create the generator instance we use for the problem in a later code block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7sxLrevqnZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d321da-7747-49e7-8094-3de94f9dfbec"
      },
      "source": [
        "# Specify the dimension of the noise vector\n",
        "noise_dim = 100\n",
        "# Get the generator model\n",
        "generator = get_generator(noise_dim)\n",
        "# Summarize the model\n",
        "generator.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 6272)              633472    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)   (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "reshape_4 (Reshape)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_8 (Conv2DTr (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_9 (Conv2DTr (None, 28, 28, 64)        73792     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 28, 28, 1)         3137      \n",
            "=================================================================\n",
            "Total params: 857,985\n",
            "Trainable params: 857,985\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU3AIrmCqnZu"
      },
      "source": [
        "Obviously we want to generate this noise from something simple so that we can sample from the same distribution later. So we use simple independent Gaussian noise.\n",
        "\n",
        "We create a function that will generate as many of these noise vectors as we wish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e833MKtMqnZv"
      },
      "source": [
        "# Generate independent Gaussian noise as input for the generator\n",
        "def generate_input_noise(noise_dim, num_vectors):\n",
        "    # Generate independent Gaussian noise\n",
        "    noise_input = rng.standard_normal(noise_dim * num_vectors)\n",
        "    # Reshape into a 2d array\n",
        "    noise_input = noise_input.reshape(num_vectors, noise_dim)\n",
        "    return noise_input"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfkn3IuQyv4U"
      },
      "source": [
        "Now we create a function to generate fake images from the noise vectors using the generator. We will also get this function to return labels indicating that the images are fake (we represent this by 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-HS7E0DyrzR"
      },
      "source": [
        "# Generate n fake images using the generator\n",
        "def generate_fake_images(generator, noise_dim, n_images):\n",
        "    # Generate noise vectors\n",
        "    noise = generate_input_noise(noise_dim, n_images)\n",
        "    # Use generator to create fake images from noise vectors\n",
        "    fakes = generator.predict(noise)\n",
        "    # create 'fake' class labels (0)\n",
        "    labels = np.zeros((n_images, 1))\n",
        "    return fakes, labels"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rvHT-HVz8I_"
      },
      "source": [
        "Let's also create a function that plot's fake images created by the generator so we look at them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oQgZUJtywl6"
      },
      "source": [
        "# Plot fake images created by generator from random noise\n",
        "def plot_generated_images(generator,noise_dim=100,n_images=25):\n",
        "    # Create the fake images (we don't need the labels here)\n",
        "    X, _ = generate_fake_images(generator, noise_dim, n_images)\n",
        "    # Plot the fake images\n",
        "    for i in range(n_images):\n",
        "        pyplot.subplot(5, 5, 1 + i)\n",
        "        pyplot.axis('off')\n",
        "        pyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
        "    pyplot.show()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzIYEk7d1PcE"
      },
      "source": [
        "Now we will create a function to make our GAN. This will involve putting the discriminator and generator together into a single model. We will also want to be able to treat them as individual models as well, so we will return (1) the discriminator, (2) the generator, and (3) the combined GAN.\n",
        "\n",
        "Note that we will make the weights in the discriminator non-trainable in the combined GAN model. This means that when we train the GAN we are actually only optimizing the weights in the generator. I discuss this further after we define the train function below.\n",
        "\n",
        "Once again, we will compile the model in the function. This is the optimizer that will be used for training the generator (because of the above). If you want to play around with the optimizer change the code inside the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-nlZB3vqnZx"
      },
      "source": [
        "# Create the discriminator, generator and GAN networks.\n",
        "# Compile networks requiring compilation within function.\n",
        "def get_gan_models(noise_dim=100):\n",
        "    # Create the discriminator (compiled internally)\n",
        "    discriminator = get_discriminator()\n",
        "    # Create the generator\n",
        "    generator = get_generator(noise_dim)\n",
        "    \n",
        "    # Make weights in the discriminator not trainable\n",
        "    discriminator.trainable = False\n",
        "    \n",
        "    # Make GAN\n",
        "    inputs = Input((noise_dim,))\n",
        "    gan = Model(inputs,discriminator(generator(inputs)))\n",
        "    \n",
        "    # Compile model\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    \n",
        "    return discriminator,generator,gan"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE43_V3L4So7"
      },
      "source": [
        "Now let's finally get our networks. If you want to change the noise dimension we work with in the problem, change the value here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idpsovn34WHw"
      },
      "source": [
        "noise_dim=100\n",
        "discriminator,generator,gan=get_gan_models(noise_dim)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH6IC5KBgMto"
      },
      "source": [
        "We are going to code a manual implementation of the training loop. This is so we can implement appropriate training for the discriminater and generator.\n",
        "\n",
        "Note we do not use validation data, and such data makes little sense in this context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgWX8PzE3-JM"
      },
      "source": [
        "# #Iter 1\n",
        "# # Train the generator and discriminator\n",
        "# def train(\n",
        "#     gan, \n",
        "#     generator,\n",
        "#     discriminator,\n",
        "#     dataset, \n",
        "#     noise_dim=100, \n",
        "#     epochs=100, \n",
        "#     batch_size=256\n",
        "# ):\n",
        "#     # We keep the amount of work done per 'epoch' matching\n",
        "#     # the dataset size, though in reality this is quite arbitrary.\n",
        "#     batches_per_epoch = int(dataset.shape[0] / batch_size)\n",
        "#     half_batch = int(batch_size / 2)\n",
        "#     # Iterate through desired number of epochs\n",
        "#     for i in range(epochs):\n",
        "#       # Iterate through batches\n",
        "#       d_loss_list = []\n",
        "#       g_loss_list = []\n",
        "#       for j in range(batches_per_epoch):\n",
        "#         # Train the discriminator            \n",
        "#         # Get randomly selected real images\n",
        "#         X_real, Y_real = select_real_images(dataset, half_batch)\n",
        "#         # Generate fake images\n",
        "#         X_fake, Y_fake = generate_fake_images(generator, noise_dim, half_batch)\n",
        "#         # Create training set for the discriminator\n",
        "#         X, Y = np.vstack((X_real, X_fake)), np.vstack((Y_real, Y_fake))\n",
        "#         # Update discriminator model weights\n",
        "#         d_loss, _ = discriminator.train_on_batch(X, Y)\n",
        "#         d_loss_list.append(d_loss) \n",
        "\n",
        "#         # Train the generator\n",
        "#         # Prepare input noise\n",
        "#         X_gan = generate_input_noise(noise_dim, batch_size)\n",
        "#         # Create inverted labels for the fake samples\n",
        "#         # This is because the GAN/generator is trying to get the discriminator\n",
        "#         # to classify these fake images as real.\n",
        "#         Y_gan = np.ones((batch_size, 1))\n",
        "#         # Update the generator weights via the discriminator's error\n",
        "#         # Remember the discriminator's weights are fixed in the GAN,\n",
        "#         # so these will not be adjusted.\n",
        "#         g_loss = gan.train_on_batch(X_gan, Y_gan)\n",
        "#         g_loss_list.append(g_loss)\n",
        "\n",
        "\n",
        "#         # Give information about loss on this batch\n",
        "#         # print(\"Epoch: {} Batch: {}/{} Disc. Loss: {:06.5f} Gen. Loss: {:06.5f}\".format(i+1, j+1,batches_per_epoch, d_loss, g_loss))\n",
        "#         # print(\"Epoch: {} Batch: {}/{}\".format(i+1, j+1,batches_per_epoch))\n",
        "\n",
        "\n",
        "#       # Epoch performance\n",
        "#       print('Epoch: {}, Discriminator loss mean:{:06.5f}, Generator loss mean:{:06.5f}'.format(i+1,mean(d_loss_list),mean(g_loss_list)))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBGzB6CP2Ocl"
      },
      "source": [
        "def getDiscriminatorTrainingData(dataset,generator,noise_dim):\n",
        "  X_real = dataset\n",
        "  Y_real = np.ones((dataset.shape[0],1))\n",
        "\n",
        "  X_fake,Y_fake = generate_fake_images(generator, noise_dim,dataset.shape[0])\n",
        "\n",
        "  X, Y = np.vstack((X_real,X_fake)), np.vstack((Y_real,Y_fake))\n",
        "  return X,Y\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpwCV7Yg84KR"
      },
      "source": [
        "discriminator = get_discriminator()\n",
        "generator = get_generator(noise_dim)\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMOwKCDo0syX"
      },
      "source": [
        "# Iter 2, seperate training generator and discriminator in each epochs\n",
        "# Train the generator and discriminator\n",
        "def train(\n",
        "    gan, \n",
        "    generator,\n",
        "    discriminator,\n",
        "    dataset, \n",
        "    noise_dim=100, \n",
        "    epochs=100, \n",
        "    batch_size=256\n",
        "):\n",
        "    # We keep the amount of work done per 'epoch' matching\n",
        "    # the dataset size, though in reality this is quite arbitrary.\n",
        "    batches_per_epoch = int(dataset.shape[0] / batch_size)\n",
        "    # half_batch = int(batch_size / 2)\n",
        "    # Iterate through desired number of epochs\n",
        "    for i in range(epochs):\n",
        "      # Iterate through batches\n",
        "      # d_loss_list = []\n",
        "      # g_loss_list = []\n",
        "\n",
        "      # training discriminator first\n",
        "      X_disc,Y_disc = getDiscriminatorTrainingData(dataset,generator,noise_dim)\n",
        "\n",
        "      disc_earlyStopping = EarlyStopping(monitor=\"loss\", \n",
        "                              patience=4,\n",
        "                              verbose=1,\n",
        "                              # baseline=0.00001,\n",
        "                              restore_best_weights=True)\n",
        "      \n",
        "      disc_history = discriminator.fit(X_disc,\n",
        "                                       Y_disc,\n",
        "                                       epochs=10,\n",
        "                                       batch_size=1024,\n",
        "                                       callbacks=[disc_earlyStopping],\n",
        "                                       )\n",
        "\n",
        "\n",
        "      # Train the generator\n",
        "      # Prepare input noise\n",
        "      X_gan = generate_input_noise(noise_dim, dataset.shape[0])\n",
        "      # Create inverted labels for the fake samples\n",
        "      # This is because the GAN/generator is trying to get the discriminator\n",
        "      # to classify these fake images as real.\n",
        "      Y_gan = np.ones((X_gan.shape[0], 1))\n",
        "      # Update the generator weights via the discriminator's error\n",
        "      # Remember the discriminator's weights are fixed in the GAN,\n",
        "      # so these will not be adjusted.\n",
        "\n",
        "      gan_earlyStopping = EarlyStopping(monitor=\"loss\", \n",
        "                              patience=4,\n",
        "                              verbose=1,\n",
        "                              restore_best_weights=True)     \n",
        "      gan_history = gan.fit(X_gan,\n",
        "                            Y_gan,\n",
        "                            epochs = 10,\n",
        "                            batch_size = 1024,\n",
        "                            callbacks=[gan_earlyStopping]) \n",
        "\n",
        "\n",
        "      # Epoch performance\n",
        "      print('Epoch: {}, Discriminator loss mean:{:06.5f}, Generator loss mean:{:06.5f}'.format(i+1,max(disc_history.history['loss']),max(gan_history.history['loss'])))"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TLtIfeNqnZz"
      },
      "source": [
        "Making the discriminator not trainable is a clever trick in the Keras API.\n",
        "\n",
        "The trainable property impacts the model after it is compiled. The discriminator model was compiled with trainable layers, therefore the model weights in those layers will be updated when the standalone model is updated via calls to the train_on_batch() function.\n",
        "\n",
        "The discriminator model was then marked as not trainable, added to the GAN model, and compiled. In this model, the model weights of the discriminator model are not trainable and cannot be changed when the GAN model is updated via calls to the train_on_batch() function. This change in the trainable property does not impact the training of standalone discriminator model.\n",
        "\n",
        "This behavior is described in the Keras API documentation here:\n",
        "\n",
        "[How can I “freeze” Keras layers?](https://keras.io/getting-started/faq/#how-can-i-freeze-keras-layers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAOnVd-AqnZz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f62638b0-f315-431d-c61f-cce83a682896"
      },
      "source": [
        "train(gan,generator,discriminator,X)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "118/118 [==============================] - 4s 29ms/step - loss: 0.2447 - accuracy: 0.9352\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 3.2253e-04 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.4991e-04 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 8.7473e-05 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 5.4507e-05 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 3.8610e-05 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 2.6797e-05 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 2.2035e-05 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.6893e-05 - accuracy: 1.0000\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 8s 105ms/step - loss: 8.1138\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 0.0083\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 6s 97ms/step - loss: 0.0040\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 0.0027\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 0.0020\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 0.0017\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 0.0014\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 0.0012\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 6s 97ms/step - loss: 0.0011\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 0.0010\n",
            "Epoch: 1, Discriminator loss mean:0.09001, Generator loss mean:3.49089\n",
            "Epoch 1/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.2940e-05 - accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.0357e-05 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 8.5932e-06 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 7.2559e-06 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 6.1334e-06 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 5.3607e-06 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 4.6381e-06 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 4.0258e-06 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 3.4725e-06 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 3.0247e-06 - accuracy: 1.0000\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 8.9924e-04\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 8.3812e-04\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 7.8430e-04\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 7.4105e-04\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 7.0094e-04\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 6.6573e-04\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 6.3579e-04\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 6.1016e-04\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 5.8724e-04\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 5.6331e-04\n",
            "Epoch: 2, Discriminator loss mean:0.00001, Generator loss mean:0.00090\n",
            "Epoch 1/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 2.7681e-06 - accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 2.4358e-06 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 2.1574e-06 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.9912e-06 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.7144e-06 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.5571e-06 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.4710e-06 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.3138e-06 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.1460e-06 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.0563e-06 - accuracy: 1.0000\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 5.4724e-04\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 5.2644e-04\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 5.0945e-04\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 4.9702e-04\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 4.8234e-04\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 4.6880e-04\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 6s 97ms/step - loss: 4.5626e-04\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 4.4516e-04\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 4.3342e-04\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 4.2249e-04\n",
            "Epoch: 3, Discriminator loss mean:0.00000, Generator loss mean:0.00055\n",
            "Epoch 1/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 9.7855e-07 - accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 8.7550e-07 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 7.8746e-07 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 7.5023e-07 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 6.7052e-07 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 6.3943e-07 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 5.7168e-07 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 5.2246e-07 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 4.6608e-07 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 4.5171e-07 - accuracy: 1.0000\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 4.1438e-04\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 4.0412e-04\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 3.9511e-04\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 3.8734e-04\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 3.7811e-04\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 3.7053e-04\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 3.6222e-04\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 3.5559e-04\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 3.4889e-04\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 3.4118e-04\n",
            "Epoch: 4, Discriminator loss mean:0.00000, Generator loss mean:0.00041\n",
            "Epoch 1/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 4.1421e-07 - accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 3.8216e-07 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 3.4118e-07 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 3.1686e-07 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 2.9550e-07 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 2.7810e-07 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 2.6080e-07 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 2.3659e-07 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 2.2650e-07 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 2.0364e-07 - accuracy: 1.0000\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 3.3538e-04\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 3.2834e-04\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 3.2211e-04\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 3.1743e-04\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 3.1083e-04\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 3.0664e-04\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 3.0070e-04\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 2.9576e-04\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 2.9037e-04\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 2.8547e-04\n",
            "Epoch: 5, Discriminator loss mean:0.00000, Generator loss mean:0.00034\n",
            "Epoch 1/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.9385e-07 - accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.7507e-07 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.6352e-07 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.5816e-07 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.4708e-07 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.3625e-07 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.2757e-07 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.2054e-07 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.0598e-07 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 1.0235e-07 - accuracy: 1.0000\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 2.8275e-04\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 2.7778e-04\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 6s 99ms/step - loss: 2.7421e-04\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 2.7087e-04\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 2.6599e-04\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 2.6205e-04\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 2.5928e-04\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 6s 98ms/step - loss: 2.5533e-04\n",
            "Epoch 9/10\n",
            " 6/59 [==>...........................] - ETA: 5s - loss: 2.5477e-04"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-4db86d7896d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-76-133a8b0aad99>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(gan, generator, discriminator, dataset, noise_dim, epochs, batch_size)\u001b[0m\n\u001b[1;32m     56\u001b[0m                             \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                             callbacks=[gan_earlyStopping]) \n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWyxm3-eqnZ2"
      },
      "source": [
        "You may see a warning:\n",
        "\n",
        "UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
        "  'Discrepancy between trainable weights and collected trainable'\n",
        "\n",
        "Don't worry about this - it is actually doing exactly what we want.\n",
        "\n",
        "When you set certain weights to trainable or untrainable (as we did in the line: discriminator.trainable = False) this only takes effect once you compile the model. We compiled the discriminator model before this call, so its weights are still trainable when we train *the discriminator model* by batch.\n",
        "\n",
        "But the discriminator model is also a *sub-model* of our complete GAN. And the GAN model was compiled *after* we set the discriminator weights to untrainable. So the discriminator weights will not be trained when we train the GAN model by batch. Neat huh?\n",
        "\n",
        "The warning is Keras thinking we have been too clever by half and are possibly making a mistake somewhere. But we aren't. :)\n",
        "\n",
        "You could get rid of the warning by setting the discriminator trainability to True and False and then recompiling models within the training loop. But that would be a lot more work..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvPiMH3kqnZ2"
      },
      "source": [
        "#Iter 1, after 100 epochs, generator loss is 0.73962\n",
        "plot_generated_images(generator,100,25)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}